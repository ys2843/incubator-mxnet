% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mxnet_generated.R
\name{mx.symbol.lamb_update_phase1}
\alias{mx.symbol.lamb_update_phase1}
\title{lamb_update_phase1:Phase I of lamb update it performs the following operations and returns g:.}
\usage{
mx.symbol.lamb_update_phase1(...)
}
\arguments{
\item{weight}{NDArray-or-Symbol
Weight}

\item{grad}{NDArray-or-Symbol
Gradient}

\item{mean}{NDArray-or-Symbol
Moving mean}

\item{var}{NDArray-or-Symbol
Moving variance}

\item{beta1}{float, optional, default=0.899999976
The decay rate for the 1st moment estimates.}

\item{beta2}{float, optional, default=0.999000013
The decay rate for the 2nd moment estimates.}

\item{epsilon}{float, optional, default=9.99999997e-07
A small constant for numerical stability.}

\item{t}{int, required
Index update count.}

\item{bias.correction}{boolean, optional, default=1
Whether to use bias correction.}

\item{wd}{float, required
Weight decay augments the objective function with a regularization term that penalizes large weights. The penalty scales with the square of the magnitude of each weight.}

\item{rescale.grad}{float, optional, default=1
Rescale gradient to grad = rescale_grad*grad.}

\item{clip.gradient}{float, optional, default=-1
Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient), -clip_gradient).}

\item{name}{string, optional
Name of the resulting symbol.}
}
\value{
out The result mx.symbol
}
\description{
Link to paper: https://arxiv.org/pdf/1904.00962.pdf
}
\details{
.. math::
    \begin{gather*}
    grad = grad * rescale_grad
    if (grad < -clip_gradient)
    then
         grad = -clip_gradient
    if (grad > clip_gradient)
    then
         grad = clip_gradient

    mean = beta1 * mean + (1 - beta1) * grad;
    variance = beta2 * variance + (1. - beta2) * grad ^ 2;

    if (bias_correction)
    then
         mean_hat = mean / (1. - beta1^t);
         var_hat = var / (1 - beta2^t);
         g = mean_hat / (var_hat^(1/2) + epsilon) + wd * weight;
    else
         g = mean / (var_data^(1/2) + epsilon) + wd * weight;
    \end{gather*}



Defined in src/operator/optimizer_op.cc:L944
}
