% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mxnet_generated.R
\name{mx.io.ThreadedDataLoader}
\alias{mx.io.ThreadedDataLoader}
\title{Returns a threaded data loader iterator.}
\usage{
mx.io.ThreadedDataLoader(...)
}
\arguments{
\item{num.workers}{int, optional, default='0'
Number of thread workers.}

\item{dataset}{long, required
Pointer to shared Dataset.}

\item{sampler}{long, required
Pointer to Sampler.}

\item{batchify.fn}{long, required
Pointer to Batchify function.}

\item{pin.device.id}{int, optional, default='-1'
If not negative, will move data to pinned memory.}

\item{prefetch.buffer}{long (non-negative), optional, default=4
Maximum number of batches to prefetch.}

\item{ctx}{{'cpu', 'cpu_pinned', 'gpu'},optional, default='gpu'
Context data loader optimized for. Note that it only indicates the optimization strategy for devices, by no means the prefetcher will load data to GPUs. If ctx is 'cpu_pinned' and device_id is not -1, it will use cpu_pinned(device_id) as ctx}

\item{device.id}{int, optional, default='-1'
The default device id for context. -1 indicate it's on default device}

\item{dtype}{{None, 'bfloat16', 'float16', 'float32', 'float64', 'int32', 'int64', 'int8', 'uint8'},optional, default='None'
Output data type. ``None`` means no change.}
}
\value{
iter The result mx.dataiter
}
\description{
Defined in src/io/dataloader.cc:L180
}
